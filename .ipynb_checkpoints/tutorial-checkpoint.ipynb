{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The tool was developped based on the following dependencies:\n",
    "\n",
    "1. PyTorch (1.1 or greater).\n",
    "2. NumPy (1.16 or greater).\n",
    "3. tqdm (4.31 or greater).\n",
    "\n",
    "Please note that the dependencies may require Python version 3.6 or greater. It is recommemded to install and maintain all dependencies by using [`conda`](https://www.anaconda.com/) or [`pip`](https://pypi.org/project/pip/). For PyTorch installation, especially when GPU acceleration is needed, additional effort may be required. Please check the official websites of [PyTorch](https://pytorch.org/get-started/locally/) and [CUDA](https://developer.nvidia.com/cuda-downloads) for detailed instructions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. How to Use"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After all dependencies being resolved, no installation is further required. You can use the tool either through command-line or function calls in your code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Data format"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All antibody protein sequences must be stored in plain-text format. A sequence consists of 20 amino acid symbol letters along with `\"-\"` to indicate gap. Sequences are deliminated by one single line-break. Please do not include spaces or extra line-breaks which will somehow confuse the program. The following lines show what the data is supposed to look like. Also, you can find sample data files under `<tool root>/data/sample/`\n",
    "\n",
    "```\n",
    "-QVQLVQS-GAEVKKPGSSVKVSCTTSG-GTFSS-----FVINWMRQAPGQGLGWRGGIMPV---\n",
    "-EVQLLES-GGGLVQPGGSLRLSCAGSG-FTFSS-----YAMSWVRQTPGKGLEWVSVISGS---\n",
    "-QVQLVES-GGGVVQSGRSLRLSCAASG-FTFRS-----HAIHWVGQAPGKGLEGVGVMSHD---\n",
    "-QVHLVQS-GAEVHKPGASLRISCKASG-YTFPN-----FFLHWVRQAPGQGLEWMGIINPI---\n",
    "-QVQLQES-GPGLMKPSGTLSLTCDVSG-ASISN----TNWWGWVRQPPGLGLEWIGEIHH----\n",
    "```\n",
    "\n",
    "If you want to generate data using Windows notepad, please be careful what the underlying line-break symbol is. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Through function calls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.1 Initialization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**`ablstm.ModelLSTM.__init__()`** initializes an LSTM model with the given paramters.\n",
    "\n",
    "Parameters:\n",
    "\n",
    "1. `embedding_dim`: Embedding layer dimensions.\n",
    "2. `hidden_dim`: Hiddden layer dimensions.\n",
    "3. `device`: Device that the model will be mounted on.\n",
    "4. `gapped`: Indicate whether the input sequences contains gaps.\n",
    "5. `fixed_len`: Indicate whether the input sequences share equal length."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model initialized.\n"
     ]
    }
   ],
   "source": [
    "from ablstm import ModelLSTM\n",
    "\n",
    "# initialize model\n",
    "# change device to 'cpu' if CUDA is not working properly\n",
    "model = ModelLSTM(embedding_dim=64, hidden_dim=64, device='cuda:0', gapped=True, fixed_len=True)\n",
    "print('Model initialized.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.2 Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**`ablstm.ModelLSTM.fit()`** fits the model via the given training and validation data. If GPU is available and CUDA is properly installed, you can assign `device` to be `\"cuda:0\"` (or `\"cuda:1\"` and so on if you have more GPUs) that will greatly accelerate the training process. For `fixed_len`, you can set it `False` without any issue, but when the sequence lengths are assured to be the same, setting it `True` will help speed up the computation as well. `save_model` is optional, if a valid path is given, model will be saved after each epoch as long as the validation performance is better than the past.\n",
    "\n",
    "Parameters:\n",
    "\n",
    "1. `trn_fn`: Data file for training.\n",
    "2. `vld_fn`: Data file for validation.\n",
    "3. `n_epoch`: Number of epochs.\n",
    "4. `trn_batch_size`: Batch size during training. `-1` means whole batch.\n",
    "5. `vld_batch_size`: Batch size during validation. `-1` means whole batch.\n",
    "6. `lr`: Learning rate.\n",
    "7. `save_fp`: Path to save models. `None` means training without saving."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 000 (TRN): 100%|| 357071/357071 [01:16<00:00, 4674.68seq/s, loss=0.771657, acc=0.799637]\n",
      "          (VLD): 100%|| 76515/76515 [00:04<00:00, 18580.62seq/s, loss=0.666901, acc=0.828263]\n",
      "Epoch 001 (TRN): 100%|| 357071/357071 [01:16<00:00, 4676.30seq/s, loss=0.648531, acc=0.833507]\n",
      "          (VLD): 100%|| 76515/76515 [00:04<00:00, 18855.35seq/s, loss=0.635343, acc=0.837485]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done.\n"
     ]
    }
   ],
   "source": [
    "# data files\n",
    "trn_fn = './data/sample/human_train.txt'\n",
    "vld_fn = './data/sample/human_val.txt'\n",
    "\n",
    "# fit model w/o save\n",
    "model.fit(trn_fn=trn_fn, vld_fn=vld_fn, n_epoch=2, trn_batch_size=128, vld_batch_size=512, lr=.002, save_fp=None)\n",
    "# # fit model w/ save\n",
    "# model.fit(trn_fn=trn_fn, vld_fn=vld_fn, n_epoch=2, trn_batch_size=128, vld_batch_size=512, lr=.002, save_fp='./saved_models/tmp')\n",
    "print('Done.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.3 Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**`ablstm.ModelLSTM.eval()`** scores the given sequences. To maximize evaluation speed, batch size is prefered to be as large as possible, but if there is any memory or GPU memory issue, please reduce the batch size.\n",
    "\n",
    "Parameters:\n",
    "\n",
    "1. `fn`: Data file for evaluation.\n",
    "2. `batch_size`: Batch size. -1 means whole batch.\n",
    "\n",
    "Returns:\n",
    "\n",
    "1. 1-D NumPy array consists of all sequences' scores. Order is preserved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating human sequences...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 76515/76515 [00:06<00:00, 12046.95seq/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating mouse sequences...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 500000/500000 [00:41<00:00, 11817.00seq/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done.\n"
     ]
    }
   ],
   "source": [
    "# data file names\n",
    "human_tst_fn = './data/sample/human_test.txt'\n",
    "mouse_tst_fn = './data/sample/mouse_test.txt'\n",
    "\n",
    "# evaluate\n",
    "print('Evaluating human sequences...')\n",
    "human_tst_scores = model.eval(fn=human_tst_fn, batch_size=512)\n",
    "print('Evaluating mouse sequences...')\n",
    "mouse_tst_scores = model.eval(fn=mouse_tst_fn, batch_size=512)\n",
    "print('Done.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's visualize the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1a73f9a5828>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.hist(human_tst_scores, bins=100, alpha=0.8, density=True, label='Human')\n",
    "plt.hist(mouse_tst_scores, bins=100, alpha=0.8, density=True, label='Mouse')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.4 Save & Load"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**`ablstm.ModelLSTM.save()`** saves model.\n",
    "\n",
    "Parameters:\n",
    "\n",
    "1. `fn`: Save file name."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**`ablstm.ModelLSTM.load()`** loads model from the given file. Please note that when `load()` method is invoked, all parameters will be overloaded except `device`. You may call `to()` method to switch among different devices.\n",
    "\n",
    "Parameters:\n",
    "\n",
    "1. `fn`: Load file name.\n",
    "\n",
    "Returns:\n",
    "\n",
    "1. Loaded model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**`ablstm.ModelLSTM.to()`** reassigns device.\n",
    "\n",
    "Parameters:\n",
    "\n",
    "1. `device`: Device to mount."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to ./saved_models/tmp/model_tmp.npy.\n",
      "Model loaded from ./saved_models/tmp/model_tmp.npy.\n"
     ]
    }
   ],
   "source": [
    "# save model\n",
    "model.save('./saved_models/tmp/model_tmp.npy')\n",
    "print('Model saved to ./saved_models/tmp/model_tmp.npy.')\n",
    "\n",
    "# load model\n",
    "model_loaded = ModelLSTM()\n",
    "model_loaded.load('./saved_models/tmp/model_tmp.npy')\n",
    "print('Model loaded from ./saved_models/tmp/model_tmp.npy.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Through command-line"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3.1 Model configuration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since neural network may have numerous parameters to configure that can appear excessively verbose if we pass all of them by commands. Most of the parameters, therefore, are stored in `ablstm.config` with XML format. The structure and the tag names exactly follow their corresponding Python class definition. Here is a sample XML configuration file. Please refer **section 2.2** for detailed description of those parameters.\n",
    "\n",
    "```xml\n",
    "<?xml version=\"1.0\"?>\n",
    "<ablstm>\n",
    "    <__init__>\n",
    "        <embedding_dim>64</embedding_dim>\n",
    "        <hidden_dim>64</hidden_dim>\n",
    "        <gapped>True</gapped>\n",
    "        <fixed_len>True</fixed_len>\n",
    "    </__init__>\n",
    "    <fit>\n",
    "        <n_epoch>8</n_epoch>\n",
    "        <trn_batch_size>128</trn_batch_size>\n",
    "        <vld_batch_size>512</vld_batch_size>\n",
    "        <lr>0.002</lr>\n",
    "    </fit>\n",
    "    <eval>\n",
    "        <batch_size>512</batch_size>\n",
    "    </eval>\n",
    "</ablstm>\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3.2 Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Manuel**\n",
    "\n",
    "```\n",
    "usage: ablstm.py fit [-h] [-l L] [-c C] [-d D] TRN_FN VLD_FN SAVE_FP\n",
    "\n",
    "positional arguments:\n",
    "  TRN_FN      training data file\n",
    "  VLD_FN      validation data file\n",
    "  SAVE_FP     model save path\n",
    "\n",
    "optional arguments:\n",
    "  -h, --help  show this help message and exit\n",
    "  -l L        model file to load (default: \"\")\n",
    "  -c C        configuration XML file (default: \"./ablstm.config\")\n",
    "  -d D        device (default: \"cpu\")\n",
    "```\n",
    "\n",
    "**Example**\n",
    "\n",
    "If you want to start a fresh training:\n",
    "\n",
    "```zsh\n",
    "> python ablstm.py fit ./data/sample/human_train.txt ./data/sample/human_val.txt ./saved_models/tmp\n",
    "```\n",
    "\n",
    "If you want to load a saved model and resume training:\n",
    "\n",
    "```zsh\n",
    "> python ablstm.py fit ./data/sample/human_train.txt ./data/sample/human_val.txt ./saved_models/tmp -l ./saved_models/tmp/model_tmp.npy\n",
    "```\n",
    "\n",
    "If you want to point to a configuration file other than `ablstm.config`:\n",
    "```zsh\n",
    "> python ablstm.py fit ./data/sample/human_train.txt ./data/sample/human_val.txt ./saved_models/tmp -c ./ablstm_new.config\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3.3 Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Manuel**\n",
    "\n",
    "```\n",
    "usage: ablstm.py eval [-h] [-c C] [-d D] TST_FN MDL_FN SCR_FN\n",
    "\n",
    "positional arguments:\n",
    "  TST_FN      evaluation data file\n",
    "  MDL_FN      model file to load\n",
    "  SCR_FN      file to save scores\n",
    "\n",
    "optional arguments:\n",
    "  -h, --help  show this help message and exit\n",
    "  -c C        configuration XML file (default: \"./ablstm.config\")\n",
    "  -d D        device (default: \"cpu\")\n",
    "```\n",
    "\n",
    "**Example**\n",
    "\n",
    "```zsh\n",
    "> python ablstm.py eval ./data/sample/human_test.txt ./saved_models/tmp/model_tmp.npy ./results/result_human_test.txt\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
